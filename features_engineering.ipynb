{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mne.io import RawArray\n",
    "from mne.channels import read_montage\n",
    "from mne.epochs import concatenate_epochs\n",
    "from mne import create_info, find_events, Epochs, concatenate_raws, pick_types, EpochsArray, EvokedArray\n",
    "from mne.decoding import CSP\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from glob import glob\n",
    "\n",
    "from scipy.signal import butter, lfilter, convolve, boxcar\n",
    "from joblib import Parallel, delayed\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "def creat_mne_raw_object(fname,read_events=True):\n",
    "    \"\"\"Create a mne raw instance from csv file\"\"\"\n",
    "    # Read EEG file\n",
    "    data = pd.read_csv(fname)\n",
    "    \n",
    "    # get chanel names\n",
    "    ch_names = list(data.columns[1:])\n",
    "    \n",
    "    # read EEG standard montage from mne\n",
    "    montage = read_montage('standard_1005',ch_names)\n",
    "\n",
    "    ch_type = ['eeg']*len(ch_names)\n",
    "    data = 1e-6*np.array(data[ch_names]).T\n",
    "    \n",
    "    if read_events:\n",
    "        # events file\n",
    "        ev_fname = fname.replace('_data','_events')\n",
    "        # read event file\n",
    "        events = pd.read_csv(ev_fname)\n",
    "        events_names = events.columns[1:]\n",
    "        events_data = np.array(events[events_names]).T\n",
    "        \n",
    "        # define channel type, the first is EEG, the last 6 are stimulations\n",
    "        ch_type.extend(['stim']*6)\n",
    "        ch_names.extend(events_names)\n",
    "        # concatenate event file and data\n",
    "        data = np.concatenate((data,events_data))\n",
    "        \n",
    "    # create and populate MNE info structure\n",
    "    info = create_info(ch_names,sfreq=500.0, ch_types=ch_type, montage=montage)\n",
    "    info['filename'] = fname\n",
    "    \n",
    "    # create raw object \n",
    "    raw = RawArray(data,info,verbose=False)\n",
    "    \n",
    "    return raw\n",
    "\n",
    "subjects = range(7,13)\n",
    "ids_tot = []\n",
    "pred_tot = []\n",
    "\n",
    "# design a butterworth bandpass filter \n",
    "freqs = [7,30]\n",
    "b,a = butter(5,np.array(freqs)/250.0,btype='bandpass')\n",
    "nr_lowpass = 5\n",
    "\n",
    "b_low,a_low = butter(5,(0.2)/250.0,btype='lowpass')\n",
    "b_low1,a_low1 = butter(5,(0.4)/250.0,btype='lowpass')\n",
    "b_low2,a_low2 = butter(5,(0.6)/250.0,btype='lowpass')\n",
    "b_low3,a_low3 = butter(5,1/250.0,btype='lowpass')\n",
    "\n",
    "# CSP parametersc\n",
    "# Number of spatial filter to use\n",
    "nfilters = 4\n",
    "\n",
    "# convolution\n",
    "# window for smoothing features\n",
    "nwin = 250\n",
    "\n",
    "# training subsample\n",
    "subsample = 10\n",
    "\n",
    "# submission file\n",
    "submission_file = 'beat_the_benchmark.csv'\n",
    "cols = ['HandStart','FirstDigitTouch',\n",
    "        'BothStartLoadPh','LiftOff',\n",
    "        'Replace','BothReleased']\n",
    "\n",
    "for subject in subjects:\n",
    "    epochs_tot = []\n",
    "    y = []\n",
    "\n",
    "    ################ READ DATA ################################################\n",
    "    fnames =  glob('/home/aditi/Downloads/all/validation/subj%d_series*_data.csv' % (subject))\n",
    "    \n",
    "    # read and concatenate all the files\n",
    "    raw = concatenate_raws([creat_mne_raw_object(fname) for fname in fnames])\n",
    "        \n",
    "    # pick eeg signal\n",
    "    picks_data = pick_types(raw.info,eeg=True)\n",
    "    \n",
    "    # Filter data for alpha frequency and beta band\n",
    "    # Note that MNE implement a zero phase (filtfilt) filtering not compatible\n",
    "    # with the rule of future data.\n",
    "    # Here we use left filter compatible with this constraint. \n",
    "    # The function parallelized for speeding up the script\n",
    "    \n",
    "    low_feat = np.zeros(np.shape(raw._data))\n",
    "    low_feat1 = np.zeros(np.shape(raw._data))\n",
    "    \n",
    "    low_feat2 = np.zeros(np.shape(raw._data))\n",
    "    low_feat3 = np.zeros(np.shape(raw._data))\n",
    "    low_feat[picks_data] = np.array(Parallel(n_jobs=-1)(delayed(lfilter)(b_low,a_low,raw._data[i]) for i in picks_data))\n",
    "    low_feat1[picks_data] = np.array(Parallel(n_jobs=-1)(delayed(lfilter)(b_low1,a_low1,raw._data[i]) for i in picks_data))\n",
    "    low_feat2[picks_data] = np.array(Parallel(n_jobs=-1)(delayed(lfilter)(b_low2,a_low2,raw._data[i]) for i in picks_data))\n",
    "    low_feat3[picks_data] = np.array(Parallel(n_jobs=-1)(delayed(lfilter)(b_low3,a_low3,raw._data[i]) for i in picks_data))\n",
    "    raw._data[picks_data] = np.array(Parallel(n_jobs=-1)(delayed(lfilter)(b,a,raw._data[i]) for i in picks_data))\n",
    "    \n",
    "    ################ CSP Filters training #####################################\n",
    "    # get event posision corresponding to Replace\n",
    "    events_1 = find_events(raw,stim_channel='Replace', verbose=False)\n",
    "    # epochs signal for 1.5 second before the movement\n",
    "    epochs_1 = Epochs(raw, events_1, {'Replace': 1}, -0.2, 0.8, proj=False,\n",
    "                    picks=picks_data, baseline=None, preload=True, verbose=False)\n",
    "    \n",
    "    epochs_tot.append(epochs_1)\n",
    "    y.extend([1]*len(epochs_1))\n",
    "    \n",
    "    \n",
    "    events_2 = find_events(raw,stim_channel='HandStart', verbose=False)\n",
    "    epochs_2 = Epochs(raw, events_2, {'HandStart' : 1}, -0.2, 0.8, proj=False,\n",
    "                    picks=picks_data, baseline=None, preload=True, verbose=False)\n",
    "    \n",
    "    epochs_tot.append(epochs_2)\n",
    "    y.extend([2]*len(epochs_2))\n",
    "    \n",
    "    events_3 = find_events(raw,stim_channel='FirstDigitTouch', verbose=False)\n",
    "    epochs_3 = Epochs(raw, events_3, {'FirstDigitTouch' : 1}, -0.2, 0.8, proj=False,\n",
    "                    picks=picks_data, baseline=None, preload=True, verbose=False)\n",
    "    \n",
    "    epochs_tot.append(epochs_3)\n",
    "    y.extend([3]*len(epochs_3))\n",
    "    \n",
    "    events_4 = find_events(raw,stim_channel='BothStartLoadPh', verbose=False)\n",
    "    epochs_4 = Epochs(raw, events_4, {'BothStartLoadPh' : 1}, -0.2, 0.8, proj=False,\n",
    "                    picks=picks_data, baseline=None, preload=True, verbose=False)\n",
    "    \n",
    "    epochs_tot.append(epochs_4)\n",
    "    y.extend([4]*len(epochs_4))\n",
    "    \n",
    "    \n",
    "    events_5 = find_events(raw,stim_channel='LiftOff', verbose=False)\n",
    "    epochs_5 = Epochs(raw, events_5, {'LiftOff' : 1}, -0.2, 0.8, proj=False,\n",
    "                    picks=picks_data, baseline=None, preload=True, verbose=False)\n",
    "    \n",
    "    epochs_tot.append(epochs_5)\n",
    "    y.extend([5]*len(epochs_5))\n",
    "    \n",
    "    events_6 = find_events(raw,stim_channel='BothReleased', verbose=False)\n",
    "    epochs_6 = Epochs(raw, events_6, {'BothReleased' : 1}, -0.2, 0.8, proj=False,\n",
    "                    picks=picks_data, baseline=None, preload=True, verbose=False)\n",
    "    \n",
    "    epochs_tot.append(epochs_6)\n",
    "    y.extend([6]*len(epochs_6))\n",
    "    \n",
    "    # Concatenate all epochs\n",
    "    epochs = concatenate_epochs(epochs_tot)\n",
    "    \n",
    "    # get data \n",
    "    X = epochs.get_data()\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # train CSP\n",
    "    csp = CSP(n_components=nfilters, reg='ledoit_wolf')\n",
    "    csp.fit(X,y)\n",
    "    \n",
    "    ################ Create Training Features #################################\n",
    "    # apply csp filters and rectify signal\n",
    "    feat = np.dot(csp.filters_[0:nfilters],raw._data[picks_data])**2\n",
    "    feat1 = np.dot(csp.filters_[0:nfilters],low_feat[picks_data])**2\n",
    "    feat2 = np.dot(csp.filters_[0:nfilters],low_feat1[picks_data])**2\n",
    "    feat3 = np.dot(csp.filters_[0:nfilters],low_feat2[picks_data])**2\n",
    "    feat4 = np.dot(csp.filters_[0:nfilters],low_feat3[picks_data])**2\n",
    "    # smoothing by convolution with a rectangle window    \n",
    "    feate=np.concatenate((feat,feat1,feat2,feat3,feat4),axis=0)\n",
    "    feattr = feate\n",
    "\n",
    "    labels = raw._data[32:]\n",
    "    \n",
    "    \n",
    "    features_labels = np.concatenate((labels, feattr), axis=0).T\n",
    "    submission = pd.DataFrame(features_labels)\n",
    "    submission.to_csv('/home/aditi/Downloads/all/features/subj%d_series_data.csv' % (subject),\n",
    "                      index_label='id',float_format='%.5f')\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
