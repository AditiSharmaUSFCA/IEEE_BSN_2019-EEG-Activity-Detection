{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Grasp and Lift Action - EEG Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we fetch the data from Mongo DB into an EMR cluster and develop several machine learning models for aacurately predicting the event type from the eeg signals. \n",
    "We compare the performance of models in terms of both area under the ROC curve (AUC) and time taken to classify the test data.\n",
    "The raw EEG signals have been pre-processed and stored in Mongo DB along with their corresponding event data. The pre-processing step is part of another notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import os\n",
    "pyspark_submit_args = '--packages org.mongodb.spark:mongo-spark-connector_2.11:2.4.0 pyspark-shell'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = pyspark_submit_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import *\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"myApp\") \\\n",
    ".config(\"spark.mongodb.input.uri\", \"mongodb://34.219.77.22/msds697.eeg\")\\\n",
    ".config(\"spark.executor.memory\", \"22g\")\\\n",
    ".config(\"spark.driver.memory\", \"10g\").config(\"spark.memory.offHeap.enabled\",True)\\\n",
    ".config(\"spark.memory.offHeap.size\", \"3g\")\\\n",
    ".getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reading the data from MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "target_cols = [str(x) for x in range(6)]\n",
    "feature_cols = [str(x) for x in range(6,26)]\n",
    "\n",
    "va = VectorAssembler(outputCol=\"features\", inputCols=feature_cols)\n",
    "\n",
    "lpoints = va.transform(df).select(\"features\", (df['0']).alias('HandStart'),\\\n",
    "                                  (df['1']).alias('FirstDigitTouch'),\\\n",
    "                                  (df['2']).alias('BothStartLoadPhase'),\\\n",
    "                                  (df['3']).alias('LiftOff'),\\\n",
    "                                  (df['4']).alias('Replace'),\\\n",
    "                                  (df['5']).alias('BothReleased'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splits=lpoints.randomSplit([0.8,0.2], seed=42 )\n",
    "eeg_train = splits[0].cache()\n",
    "eeg_valid=splits[1].cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area Under ROC HandStart : 0.5209817175371723\n",
      "area Under ROC FirstDigitTouch : 0.5654686820170102\n",
      "area Under ROC BothStartLoadPhase : 0.5626207148258029\n",
      "area Under ROC LiftOff : 0.5770476860632803\n",
      "area Under ROC Replace : 0.5965438220639617\n",
      "area Under ROC BothReleased : 0.5812007968808708\n",
      "Time taken for logistic regression 829.0077323913574s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#labels are events that we are trying to classify\n",
    "labels= ['HandStart','FirstDigitTouch', 'BothStartLoadPhase', 'LiftOff', 'Replace', 'BothReleased']\n",
    "#iterating over the events and fitting a logisitic regression model and train it for each event\n",
    "start= time.time()\n",
    "for label in labels:\n",
    "    lr = LogisticRegression(regParam=0.01, maxIter=100, fitIntercept=True, labelCol=label)\n",
    "    lrmodel = lr.fit(eeg_train.select('features',label))\n",
    "    validpredicts = lrmodel.transform(eeg_valid.select('features',label))\n",
    "    bceval = BinaryClassificationEvaluator(labelCol=label)\n",
    "    auc = bceval.evaluate(validpredicts)\n",
    "    duration= time.time()-start\n",
    "    print ('area Under ROC ' + label+ \" : \" + str(auc))\n",
    "print('Time taken for logistic regression '+ str(duration) + 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area Under ROC HandStart : 0.878859706306801\n",
      "area Under ROC FirstDigitTouch : 0.8473881048005849\n",
      "area Under ROC BothStartLoadPhase : 0.8486340197761922\n",
      "area Under ROC LiftOff : 0.8415285260668661\n",
      "area Under ROC Replace : 0.8382513282108403\n",
      "area Under ROC BothReleased : 0.8610798973492925\n",
      "Time taken for Random Forest 1761.7716419696808s\n"
     ]
    }
   ],
   "source": [
    "#labels are events that we are trying to classify\n",
    "labels= ['HandStart','FirstDigitTouch', 'BothStartLoadPhase', 'LiftOff', 'Replace', 'BothReleased']\n",
    "start= time.time()\n",
    "#iterating over the events and fitting a Random forest model and train it for each event\n",
    "for label in labels:\n",
    "    rf = RandomForestClassifier(maxDepth=10, labelCol=label)\n",
    "    rfmodel = rf.fit(eeg_train.select('features',label))\n",
    "    validpredicts = rfmodel.transform(eeg_valid.select('features',label))\n",
    "    bceval = BinaryClassificationEvaluator(labelCol=label)\n",
    "    auc = bceval.evaluate(validpredicts)\n",
    "    duration= time.time()-start\n",
    "    print ('area Under ROC ' + label+ \" : \" + str(auc))\n",
    "print('Time taken for Random Forest '+ str(duration) + 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC HandStart : 0.5176370865239852\n",
      "areaUnderROC FirstDigitTouch : 0.5469576112336251\n",
      "areaUnderROC BothStartLoadPhase : 0.5352378380935301\n",
      "areaUnderROC LiftOff : 0.536106045267316\n",
      "areaUnderROC Replace : 0.5353413731113085\n",
      "areaUnderROC BothReleased : 0.5303661353569502\n",
      "Time taken for Linear SVC  6194.433146238327s\n"
     ]
    }
   ],
   "source": [
    "#labels are events that we are trying to classify\n",
    "labels= ['HandStart','FirstDigitTouch', 'BothStartLoadPhase', 'LiftOff', 'Replace', 'BothReleased']\n",
    "start= time.time()\n",
    "#iterating over the events and fitting a logisitic regression model and train it for each event\n",
    "for label in labels:\n",
    "    svc = LinearSVC(labelCol=label)\n",
    "    svcmodel = svc.fit(eeg_train.select('features',label))\n",
    "    validpredicts = svcmodel.transform(eeg_valid.select('features',label))\n",
    "    bceval = BinaryClassificationEvaluator(labelCol=label)\n",
    "    auc = bceval.evaluate(validpredicts)\n",
    "    duration= time.time()-start\n",
    "    print ('areaUnderROC ' + label+ \" : \" + str(auc))\n",
    "print('Time taken for Linear SVC  '+ str(duration) + 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC HandStart : 0.850708214941604\n",
      "areaUnderROC FirstDigitTouch : 0.8312993115269941\n",
      "areaUnderROC BothStartLoadPhase : 0.8184384403506808\n",
      "areaUnderROC LiftOff : 0.8233671866533202\n",
      "areaUnderROC Replace : 0.794779023843368\n",
      "areaUnderROC BothReleased : 0.8525921633912922\n",
      "Time taken for Gradient Boosted Tree  3941.667410850525s\n"
     ]
    }
   ],
   "source": [
    "labels= ['HandStart','FirstDigitTouch', 'BothStartLoadPhase', 'LiftOff', 'Replace', 'BothReleased']\n",
    "start= time.time()\n",
    "for label in labels:\n",
    "    gbt = GBTClassifier(maxIter=10, maxDepth=10, labelCol=label)\n",
    "    gbtmodel = gbt.fit(eeg_train.select('features',label))\n",
    "    validpredicts = gbtmodel.transform(eeg_valid.select('features',label))\n",
    "    bceval = BinaryClassificationEvaluator(labelCol=label)\n",
    "    auc = bceval.evaluate(validpredicts)\n",
    "    duration= time.time()-start\n",
    "    print ('areaUnderROC ' + label+ \" : \" + str(auc))\n",
    "print('Time taken for Gradient Boosted Tree  '+ str(duration) + 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
